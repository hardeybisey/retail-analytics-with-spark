{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53be4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, FloatType, LongType, StructType,StructField, StringType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13066e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/13 10:32:21 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "# spark.sparkContext.setLogLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8036fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6972c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = spark.sparkContext.getConf().getAll()\n",
    "# for k, v in configs:\n",
    "#     print(f\"{k} = {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aceb791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f28600805b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56757821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|catalog|       namespace|\n",
      "+-------+----------------+\n",
      "|   demo|retail_analytics|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9694c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SHOW NAMESPACES IN demo\").show()\n",
    "# spark.sql(\"CREATE NAMESPACE demo.retail_analytics\")\n",
    "# spark.sql(\"USE demo.retail_analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a462b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://csv-input/customers.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "875457a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_address</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>customer_created_date</th>\n",
       "      <th>customer_updated_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001</td>\n",
       "      <td>604 Hampton Burg</td>\n",
       "      <td>DC</td>\n",
       "      <td>20002</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000002</td>\n",
       "      <td>6588 Robert Bypass Apt. 375</td>\n",
       "      <td>RI</td>\n",
       "      <td>02869</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000003</td>\n",
       "      <td>452 Gardner Gateway</td>\n",
       "      <td>FM</td>\n",
       "      <td>96944</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000004</td>\n",
       "      <td>29959 Olivia Brooks</td>\n",
       "      <td>NM</td>\n",
       "      <td>88319</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000005</td>\n",
       "      <td>334 Martinez Bypass</td>\n",
       "      <td>VI</td>\n",
       "      <td>00803</td>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id             customer_address customer_state customer_zip_code  \\\n",
       "0    00000001             604 Hampton Burg             DC             20002   \n",
       "1    00000002  6588 Robert Bypass Apt. 375             RI             02869   \n",
       "2    00000003          452 Gardner Gateway             FM             96944   \n",
       "3    00000004          29959 Olivia Brooks             NM             88319   \n",
       "4    00000005          334 Martinez Bypass             VI             00803   \n",
       "\n",
       "  customer_created_date customer_updated_date  \n",
       "0            2021-10-03                  None  \n",
       "1            2022-02-12                  None  \n",
       "2            2022-05-15                  None  \n",
       "3            2022-08-01                  None  \n",
       "4            2023-09-07                  None  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88bb0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, coalesce, row_number\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_schema = schema.get_customer_schema()\n",
    "\n",
    "# df = extract_raw_data(sparkapp.create_spark_session(), \"csv-input\",  \"customers.csv\", schema.get_customer_schema())\n",
    "\n",
    "window_spec = Window.partitionBy(\"customer_id\").orderBy(\"updated_date\")\n",
    "\n",
    "df.withColumnsRenamed({\n",
    "            \"customer_address\": \"address\",\n",
    "            \"customer_state\": \"state\",\n",
    "            \"customer_zip_code\": \"zip_code_prefix\",\n",
    "            \"customer_created_date\": \"created_date\",\n",
    "            \"customer_updated_date\": \"updated_date\",\n",
    "}).withColumn(\n",
    "    \"row_num\", row_number().over(window_spec)\n",
    ").filter(col(\"row_num\") == 1).select(\n",
    "        \"customer_id\",\n",
    "        \"address\",\n",
    "        \"state\",\n",
    "        \"zip_code_prefix\",\n",
    "        \"created_date\",\n",
    "        \"updated_date\"\n",
    ").drop(\"row_num\").write.mode(\"overwrite\").partitionBy(\"state\").saveAsTable(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0114e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+---------------+------------+------------+\n",
      "|customer_id|             address|state|zip_code_prefix|created_date|updated_date|\n",
      "+-----------+--------------------+-----+---------------+------------+------------+\n",
      "|   00000001|    604 Hampton Burg|   DC|          20002|  2021-10-03|        NULL|\n",
      "|   00000002|6588 Robert Bypas...|   RI|          02869|  2022-02-12|        NULL|\n",
      "|   00000003| 452 Gardner Gateway|   FM|          96944|  2022-05-15|        NULL|\n",
      "|   00000004| 29959 Olivia Brooks|   NM|          88319|  2022-08-01|        NULL|\n",
      "|   00000005| 334 Martinez Bypass|   VI|          00803|  2023-09-07|        NULL|\n",
      "+-----------+--------------------+-----+---------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"customer_id\").orderBy(\"updated_date\")\n",
    "\n",
    "df.withColumnsRenamed({\n",
    "            \"customer_address\": \"address\",\n",
    "            \"customer_state\": \"state\",\n",
    "            \"customer_zip_code\": \"zip_code_prefix\",\n",
    "            \"customer_created_date\": \"created_date\",\n",
    "            \"customer_updated_date\": \"updated_date\",\n",
    "}).withColumn(\n",
    "    \"row_num\", row_number().over(window_spec)\n",
    ").filter(col(\"row_num\") == 1).select(\n",
    "        \"customer_id\",\n",
    "        \"address\",\n",
    "        \"state\",\n",
    "        \"zip_code_prefix\",\n",
    "        \"created_date\",\n",
    "        \"updated_date\"\n",
    ").drop(\"row_num\").write.saveAsTable(\"customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41d9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.saveAsTable(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec021950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: string, customer_address: string, customer_state: string, customer_zip_code: string, customer_created_date: string, customer_updated_date: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6288dd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: string, customer_address: string, customer_state: string, customer_zip_code: string, customer_created_date: string, customer_updated_date: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1333c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, gender: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n",
    "columns = [\"name\",\"gender\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df2 = df.withColumn(\"gender\", F.expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n",
    "           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\n",
    "\n",
    "df2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912dfb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   name| gender|\n",
      "+-------+-------+\n",
      "|  James|   Male|\n",
      "|Michael| Female|\n",
      "|    Jen|unknown|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9184806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='James', gender='M'),\n",
       " Row(name='Michael', gender='F'),\n",
       " Row(name='Jen', gender='')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bd781",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2995544924.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    SELECT * FROM customers LIMIT 5\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %sql\n",
    "# SELECT * FROM customers LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f02084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----------------+---------------------+---------------------+\n",
      "|customer_id|    customer_address|customer_state|customer_zip_code|customer_created_date|customer_updated_date|\n",
      "+-----------+--------------------+--------------+-----------------+---------------------+---------------------+\n",
      "|   00000001|    604 Hampton Burg|            DC|            20002|           2021-10-03|                 NULL|\n",
      "|   00000002|6588 Robert Bypas...|            RI|            02869|           2022-02-12|                 NULL|\n",
      "|   00000003| 452 Gardner Gateway|            FM|            96944|           2022-05-15|                 NULL|\n",
      "|   00000004| 29959 Olivia Brooks|            NM|            88319|           2022-08-01|                 NULL|\n",
      "|   00000005| 334 Martinez Bypass|            VI|            00803|           2023-09-07|                 NULL|\n",
      "+-----------+--------------------+--------------+-----------------+---------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM customers LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7df8488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"UPDATE customers SET customer_updated_date='2025-08-11' WHERE customer_id=00000001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d660ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+--------------+-----------------+---------------------+---------------------+\n",
      "|customer_id|customer_address|customer_state|customer_zip_code|customer_created_date|customer_updated_date|\n",
      "+-----------+----------------+--------------+-----------------+---------------------+---------------------+\n",
      "|   00000001|604 Hampton Burg|            DC|            20002|           2021-10-03|           2025-08-11|\n",
      "+-----------+----------------+--------------+-----------------+---------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/13 10:48:52 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.7: worker lost: 172.18.0.7:33625 got disassociated\n",
      "25/09/13 10:48:52 ERROR TaskSchedulerImpl: Lost executor 2 on 172.18.0.7: worker lost: 172.18.0.7:33625 got disassociated\n",
      "25/09/13 10:48:52 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.7: worker lost: 172.18.0.7:33625 got disassociated\n",
      "25/09/13 10:48:52 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_20_0 !\n",
      "25/09/13 10:48:52 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_20_1 !\n",
      "25/09/13 10:48:52 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_20_5 !\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM customers WHERE customer_id=00000001\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c75b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 1871, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/usr/local/lib/python3.10/selectors.py\", line 469, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/opt/spark/python/pyspark/context.py\", line 381, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/opt/spark/python/pyspark/context.py\", line 2446, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "AttributeError: 'NoneType' object has no attribute 'sc'\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
