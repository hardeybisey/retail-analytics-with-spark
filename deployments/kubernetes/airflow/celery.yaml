######################################
## Airflow Worker Service
######################################
apiVersion: v1
kind: Service
metadata:
  name: airflow-worker-svc
  namespace: airflow
spec:
  type: ClusterIP
  selector:
    component: worker
  ports:
    - name: worker-port
      protocol: TCP
      port: 8793
      targetPort: worker-port
---
######################################
## Airflow Worker StatefulSet
######################################
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-worker-deployment
  namespace: airflow
  labels:
    tier: airflow
    component: airflow-worker
spec:
  serviceName: airflow-worker-svc
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: airflow-worker
  template:
    metadata:
      labels:
        tier: airflow
        component: airflow-worker
    spec:
      serviceAccountName: airflow-sa
      securityContext:
        runAsUser: 50000
        fsGroup: 0
      volumes:
        - name: airflow-data
          persistentVolumeClaim:
            claimName: airflow-pvc
        - name: config
          configMap:
            name: spark-config
      initContainers:
        - name: wait-for-airflow-migrations
          image: iadebisi/airflow-spark
          imagePullPolicy: IfNotPresent
          resources: {}
            # requests:
            #   cpu: 200m
            #   memory: 128Mi
            # limits:
            #   cpu: 400m
            #   memory: 256Mi
          volumeMounts:
            - name: airflow-data
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: config/airflow.cfg
              readOnly: true
          args:
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:
            - configMapRef:
                name: airflow-config
            - secretRef:
                name: airflow-secrets
      containers:
        - name: worker
          # image: apache/airflow:3.1.0
          image: iadebisi/airflow-spark
          imagePullPolicy: IfNotPresent
          resources: {}
            # requests:
            #   cpu: "400m"
            #   memory: "1Gi"
            # limits:
            #   cpu: "500m"
            #   memory: "2Gi"
          volumeMounts:
            - name: airflow-data
              mountPath: /opt/airflow/logs
              subPath: logs
            - name: airflow-data
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: config/airflow.cfg
              readOnly: true
            - name: airflow-data
              mountPath: /opt/airflow/dags
              subPath: dags
              readOnly: true
            - name: airflow-data
              mountPath: /opt/spark/spark_jobs
              subPath: spark_jobs
              readOnly: true
            - name: config
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
              readOnly: true
          command: []
          args:
            - bash
            - -c
            - |-
              exec airflow celery worker
          ports:
            - name: worker-port
              containerPort: 8793
              protocol: TCP
          envFrom:
            - configMapRef:
                name: airflow-config
            - secretRef:
                name: airflow-secrets
          env:
            - name: DUMB_INIT_SETSID
              value: "0"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: AWS_SECRET_ACCESS_KEY
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 5
            periodSeconds: 60
            exec:
              command:
                - sh
                - -c
                - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d celery@$(hostname)

  # volumeClaimTemplates:
  #   - apiVersion: v1
  #     kind: PersistentVolumeClaim
  #     metadata:
  #       name: logs
  #     spec:
  #       accessModes: ["ReadWriteOnce"]
  #       resources:
  #         requests:
  #           storage: 100Gi
